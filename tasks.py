import os
import re
import asyncio
import aiohttp
import openpyxl
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from celery import Celery
from sqlalchemy import create_engine, Column, Integer, String, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥—ã
load_dotenv()

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Redis –∏ Celery
REDIS_URL = os.getenv("REDIS_URL")
celery = Celery("tasks", broker=REDIS_URL)

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
DATABASE_URL = os.getenv("DATABASE_URL")
engine = create_engine(DATABASE_URL)
SessionLocal = scoped_session(sessionmaker(bind=engine))
Base = declarative_base()

# --- –ú–æ–¥–µ–ª–∏
class User(Base):
    __tablename__ = "users"
    id = Column(Integer, primary_key=True)
    email = Column(String, unique=True, nullable=False)
    password = Column(String, nullable=False)
    plan = Column(String, default="free")
    requests_used = Column(Integer, default=0)
    is_admin = Column(Integer, default=0)

class TempEmail(Base):
    __tablename__ = "temp_emails"
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    email = Column(String)

# --- –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç)
Base.metadata.create_all(bind=engine)

# --- –§–∏–ª—å—Ç—Ä—ã
EMAIL_REGEX = r"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+"
EXCLUDE_DOMAINS = ["sentry.io", "cloudflare", "example.com", "no-reply", "noreply", "support", "admin", "localhost"]

COMMON_PATHS = ["/kontakt", "/impressum", "/about", "/ueber-uns", "/info", "/contact"]

# --- –ü–æ–ª—É—á–µ–Ω–∏–µ HTML —Å —Å–∞–π—Ç–∞
async def fetch_html(session, url, retries=2):
    for attempt in range(retries):
        try:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    return await response.text()
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}: {e}")
            await asyncio.sleep(1)
    return ""

# --- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ email-–æ–≤ —Å –º–Ω–æ–∂–µ—Å—Ç–≤–∞ URL
async def extract_emails_from_url_async(urls):
    collected_emails = set()
    headers = {"User-Agent": "Mozilla/5.0"}

    async with aiohttp.ClientSession(headers=headers) as session:
        tasks = []

        for url in urls:
            base_url = url.rstrip("/")
            extended_urls = [base_url + path for path in COMMON_PATHS]
            all_urls = [base_url] + extended_urls

            for u in all_urls:
                tasks.append(fetch_html(session, u))

        responses = await asyncio.gather(*tasks)

        for html in responses:
            if not html:
                continue

            soup = BeautifulSoup(html, "html.parser")

            # 1. email'—ã –≤ —Ç–µ–∫—Å—Ç–µ
            text_emails = re.findall(EMAIL_REGEX, soup.get_text())
            collected_emails.update(text_emails)

            # 2. email'—ã –≤ mailto:
            for tag in soup.find_all("a", href=True):
                href = tag["href"]
                if "mailto:" in href:
                    email = href.split("mailto:")[1].split("?")[0]
                    collected_emails.add(email)

    # —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–ª–æ—Ö–∏–µ –∞–¥—Ä–µ—Å–∞
    filtered = [
        email for email in collected_emails
        if not any(bad in email for bad in EXCLUDE_DOMAINS)
    ]
    return list(set(filtered))

# --- –ì–ª–∞–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ Celery
@celery.task
def collect_emails_to_file(user_id, urls, max_count):
    print(f"üì• –ù–∞—á–∞–ª–æ —Å–±–æ—Ä–∞ email'–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    print(f"üîó URL-–æ–≤ –ø–µ—Ä–µ–¥–∞–Ω–æ: {len(urls)} ‚Äî {urls}")

    db = SessionLocal()

    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ email'—ã
    db.query(TempEmail).filter_by(user_id=user_id).delete()
    db.commit()

    # –°–±–æ—Ä email'–æ–≤
    try:
        emails = asyncio.run(extract_emails_from_url_async(urls))
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ email'–æ–≤: {e}")
        emails = []

    print(f"üì® –ù–∞–π–¥–µ–Ω–æ email'–æ–≤: {len(emails)}")
    print(f"üí° –°–ø–∏—Å–æ–∫ email'–æ–≤: {emails}")

    selected = emails[:max_count]  # –º–æ–∂–Ω–æ –æ—Ç–∫–ª—é—á–∏—Ç—å –ª–∏–º–∏—Ç –Ω–∞ —Ç–µ—Å—Ç

    for email in selected:
        db.add(TempEmail(user_id=user_id, email=email))
    db.commit()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "Emails"
    ws.append(["E-Mail"])
    for e in selected:
        ws.append([e])

    output_path = f"/tmp/emails_user_{user_id}.xlsx"
    wb.save(output_path)
    print(f"‚úÖ Excel-—Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")

    db.close()
